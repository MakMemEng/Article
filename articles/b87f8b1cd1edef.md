---
title: "ç”Ÿæˆç³»AIé–¢é€£ã§ã‚ˆãã¿ã‚‹â€™RAGâ€™ã£ã¦ä½•ï¼Ÿ"
emoji: "ðŸ’­"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["Azure", "OpenAI", "ChatGPT", "LangChain", "RAG"]
published: true
published_at: 2024-05-31 21:00
---
# RAGã¨ã¯ï¼Ÿ

gpt-4ã‚„gpt-3.5-turboã¯2023å¹´4æœˆã¾ã§ã®Publicãªæƒ…å ±ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ã€‚(2024å¹´2æœˆç¾åœ¨) ã—ã‹ã—ã€ã‚‚ã£ã¨æ–°ã—ã„æƒ…å ±ã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãªæƒ…å ±ã‚’ä½¿ã‚ã›ãŸã„ã“ã¨ã¯å¤šã„ã€‚

ãã“ã§ã€Promptã«æ–‡è„ˆ(context)ã‚’å…¥ã‚Œã‚‹æ–¹æ³•ã‚’ç”¨ã„ã‚‹ã€‚ æ–‡æ›¸ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦Vector Storeã«ä¿å­˜ã—ã¦ãŠãã€è³ªå•ã«é–¢ä¿‚ã—ãã†ãªæ–‡æ›¸ã‚’æ¤œç´¢ã—ã¦Promptã«å«ã‚ã€ãã®å†…å®¹ã‚’è¸ã¾ãˆã¦LLMã«å›žç­”ã•ã›ã‚‹ã€‚ ã“ã®æ‰‹æ³•ã¯æ¤œç´¢æ‹¡å¼µç”Ÿæˆ(Retrieval Augmented Generationã€é€šç§°RAG)ã¨å‘¼ã°ã‚Œã¦ã„ã‚‹ã€‚

![](/images/b87f8b1cd1edef/image.png)

## ä½¿ç”¨ä¾‹

![](/images/b87f8b1cd1edef/image(1).png)

1. `query`: ã€Œã“ã®ShellScriptã‚’å®Ÿè¡Œã—ãŸã¨ãã®ä¸€é€£ã®æµã‚Œã‚’èª¬æ˜Žã—ã¦ãã ã•ã„ã€‚ã€
2. Embedding:Â `query`ã‚’æ•°å€¤ã«å¤‰æ›(VectoråŒ–)
3. Retriever: 2ã®çµæžœã¨è¿‘ã—ã„æƒ…å ±ã‚’æ¤œç´¢
4. Prompt: ã€Œã‚ãªãŸã¯ã¤ã‚ˆã¤ã‚ˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚åˆå­¦è€…ã«ã‚‚åˆ†ã‹ã‚Šã‚„ã™ã„ã‚ˆã†ã«å›žç­”ã—ã¦ãã ã•ã„ã€‚ã€
5. 4ã®æŒ‡ç¤ºã«å¾“ã„ã€3ã®å†…å®¹ã‚’ã‚‚ã¨ã«å›žç­”ç”Ÿæˆ

## æº–å‚™

```toml
python = ">=3.9.6, <3.12"
python-dotenv = "^1.0.0"
faiss-cpu = "^1.7.4"
tiktoken = "^0.5.1"
langchain = "^0.1.4"
openai = "^1.10.0"
langchain-openai = "^0.0.5"
unstructured = "^0.13.2"
```

```python
from dotenv import load_dotenv
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# APIè¨­å®šã®å¤‰æ•°
openai_api_key = os.getenv("AZURE_OPENAI_KEY")
azure_endpoint = os.getenv("AZURE_ENDPOINT")
api_version = os.getenv("AZURE_OPENAI_VERSION")
azure_deployment = os.getenv("AZURE_OPENAI_ENGINE")
embedding_deployment = os.getenv("AZURE_OPENAI_EMBEDDING_ENGINE")

# ãƒ†ã‚­ã‚¹ãƒˆembeddingãƒ¢ãƒ‡ãƒ«
embeddings = AzureOpenAIEmbeddings(
    azure_endpoint=azure_endpoint,
    deployment=embedding_deployment,
    api_key=openai_api_key,
    api_version=api_version,
    chunk_size=1,
)

# AzureChatOpenAI
llm = AzureChatOpenAI(
    api_version=api_version,
    azure_endpoint=azure_endpoint,
    openai_api_key=openai_api_key,
    azure_deployment=azure_deployment,
    temperature=0,
)

# ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²ãƒ„ãƒ¼ãƒ«
text_splitter = CharacterTextSplitter(
    separator="\r\n",
    chunk_size=512,
    chunk_overlap=128,
    length_function=len,
)

```

## æ–‡æ›¸ã‚’Vectorå¤‰æ›ã—ã¦VectorStoreã‚’ä½œæˆ

```python
from langchain_community.document_loaders import DirectoryLoader

# ç‰¹å®šã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ç‰¹å®šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡æ›¸ã¨ã—ã¦ä½¿ç”¨
loader_sh = DirectoryLoader("./.../bash", glob="**/*.sh")

# ä¸€åº¦ã«å¤§é‡ã®æ–‡æ›¸ã‚’LLMã«æ¸¡ã™ã¨Tokenåˆ¶é™ã‚’è¶…ãˆã‚‹ãŸã‚æ–‡æ›¸ã‚’è¤‡æ•°ã®chunkã«åˆ†å‰²
docs_sh = loader_sh.load_and_split()

# VectorStoreä½œæˆ
index = FAISS.from_documents(docs_sh, embeddings)
```

```python
# ä½œæˆã—ãŸVectorStoreã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ã™ã‚‹ã“ã¨ã§ã€æ—¢ã«å¤‰æ›æ¸ˆã¿ã®VectorStoreã‚’å†åˆ©ç”¨ã§ãã‚‹
index.save_local("./sample_index")

# ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ã—ãŸVectorStoreã‚’èª­ã¿è¾¼ã‚€
index = FAISS.load_local("./sample_index/", embeddings)
```

## Promptã‚’ä½œæˆã—ã¦ã€LLMã«è³ªå•ã‚’æŠ•ã’ã‚‹

```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableParallel, RunnablePassthrough

template = """Answer the question based on the following context:
{context}

Question: {question}
"""
prompt = ChatPromptTemplate.from_template(template)
retriever = index.as_retriever()
output_parser = StrOutputParser()

setup_and_retrieval = RunnableParallel(
    {"context": retriever, "question": RunnablePassthrough()}
)
chain = setup_and_retrieval | prompt | llm | output_parser
```

```python
query = "â—‹â—‹.shã®æ§‹æˆã¨å®Ÿè¡Œã®ä¸€é€£ã®æµã‚Œã‚’èª¬æ˜Žã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€å„è¦ç´ ã®å‚ç…§ã‚³ãƒ¼ãƒ‰ã‚‚æ•™ãˆã¦ãã ã•ã„ã€‚"
result = chain.invoke(query)
print(result)
```

### å‚è€ƒ

<https://python.langchain.com/docs/expression_language/get_started>
